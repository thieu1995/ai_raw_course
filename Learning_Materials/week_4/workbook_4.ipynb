{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae6289d-998e-42ed-8ade-d9a55526d67b",
   "metadata": {},
   "source": [
    "# Workbook 4: Local Search in categorical and continuous spaces\n",
    "## Introduction\n",
    "This workbook focusses on the final search algorithm that we have discussed but not asked you to implement so far: Local Search.  \n",
    "\n",
    "We will focus on perturbative approaches\n",
    "\n",
    "To develop your understanding you will:\n",
    "- Start with a simple binary problem that local search should be able to solve.\n",
    "- Look at a binary problem local search cannot solve without some changes\n",
    "- Adapt the **SingleMemberSearch** class to work with continuous decision variables,  \n",
    "   using  continuous version of the first binary problem. \n",
    "\n",
    "## Aims of this practical\n",
    "1. To give you the experience of  implementing, and evaluating the behaviour of local search in categorical problems.\n",
    "2. To give you experience of comparing the behaviour of different search algorithms.\n",
    "3. To give you experience of evaluating the efficiency of an algorithm for a problem ( in this case path-planning) by creating different instances of a problem (mazes) to *stress-test* different methods. \n",
    "\n",
    "# This is not an assessed workbook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd62e37-11a7-4d2c-b1be-2928935831e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## reminder: Pseudocode for function SelectAndMoveFromOpenList in Local Search\n",
    "### This assumes the search process maintains track of *bestSoFar*\n",
    "<div style=\"background:#F0FFFF;font-size:18pt\">\n",
    "<p style=\"color:darkred;font-size:18pt;margin-bottom:0pt\"><em>SelectAndMoveFromOpenList</em></p>\n",
    "<dl style=\"font-size:18pt;margin-top:0pt\">\n",
    "    <dt>&nbsp;&nbsp;&nbsp;<b>IF</b> IsEmpty( open_list) <b>THEN</b> </dt>\n",
    "    <dd> RETURN None</dd>\n",
    "    <dt> &nbsp;&nbsp;&nbsp;<b>ELSE</b></dt>\n",
    "    <dd>bestChild &larr; <b>GetMemberWithHighestQuality</b>(openList)</dd>\n",
    "    <dd> <b>EMPTY</b>(openlist)&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"background:pink\">This prevents backtracking</span></dd>\n",
    "    <dd>  <b>IF</b> BetterThan(bestChild, bestSoFar) <b>THEN</b> <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;bestSoFar &larr; bestChild <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;RETURN bestChild </dd>\n",
    "    <dd> <b>ELSE</b> <br>&nbsp;&nbsp;&nbsp;&nbsp; RETURN None</dd>\n",
    "</dl>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19af297-72bb-491a-996c-a0042b2d6f9b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 1: implementing local search for a binary problem</h2>\n",
    "    <ul>\n",
    "        <li>Run the first cell to do some standard imports.</li>\n",
    "    <li>Then complete the second cell which contains an incomplete implementation of local search.</li>\n",
    "    <li> Test your implementation by running the third cell which uses your implementation to solve the <em>OneMax</em> problem. <br>\n",
    "        This is a simple binary maximisation problem where the quality is the number of the decision variables set to 1.</li>\n",
    "        </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ccbd6-c5e7-45de-a75f-483aae36409a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from candidatesolution import CandidateSolution\n",
    "from singlemembersearch import SingleMemberSearch\n",
    "from problem import Problem\n",
    "from onemaxproblem import OneMaxBinary, OneMaxContinuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3cea1-eb18-43ff-b1ac-5f5b8c46b2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalSearch(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search.\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"local search\"\n",
    "\n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        \"\"\"Pops best thing from list, clears rest of list, then returns best thing\n",
    "        relies on the presence of self.best_so_far\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next\n",
    "           working candidate (solution) taken from open list\n",
    "           if it is an improvem ent\n",
    "        None\n",
    "           IF list is empty OR next thing is worse than best so far\n",
    "        \"\"\"\n",
    "        next_soln = CandidateSolution()\n",
    "\n",
    "        # edge cases\n",
    "        if len(self.open_list) == 0:\n",
    "            self.runlog += \"LS:empty open list\\n\"\n",
    "            return None\n",
    "\n",
    "        # get best child\n",
    "        best_index = 0\n",
    "        quality = self.open_list[0].quality\n",
    "        best_so_far: int = quality\n",
    "        ## your code to put the right value from the open list into next_soln\n",
    "        \n",
    "        self.runlog += (\n",
    "            f\"\\t best child quality {best_so_far},\\n\\t best so far {self.best_so_far}\\n\"\n",
    "        )\n",
    "        # clear the openlist\n",
    "        ## Your code here\n",
    "        # always accept first move\n",
    "        if self.trials == 1:\n",
    "            better: bool = True\n",
    "        # otherwise there must be an improvement\n",
    "        # your code to return best from open list \n",
    "        #or None if it doesn't improve on self.best_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a8024-6964-4821-a605-494e24d122de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_vars = 10\n",
    "binary_onemax = OneMaxBinary(N=num_vars)\n",
    "mysearch = LocalSearch( binary_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=False,\n",
    "                        target_quality=num_vars)\n",
    "# default behaviour is to initialise with all zeroes\n",
    "# change to random initialisation\n",
    "for i in range(num_vars):\n",
    "    mysearch.open_list[0].variable_values[i] = np.random.choice(binary_onemax.value_set)\n",
    "#get new score\n",
    "quality,_ = binary_onemax.evaluate(mysearch.open_list[0].variable_values)\n",
    "mysearch.open_list[0].quality = quality\n",
    "print(f'quality of starting choices {mysearch.open_list[0].variable_values} is {quality}')\n",
    "    \n",
    "\n",
    "success = mysearch. run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch.trials} attempts.'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch.runlog}'\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff9ec1-c088-4958-a1a9-a6bd7c1ffb6a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 2: Evaluating your implementation of implementing local search</h2>\n",
    "    Once your code works and the cell above runs and finds a solution, it is time to evaluate its performance. <ul>\n",
    "    <li>Run the cell above ten times with <em>num_vars= 10</em> and note the number of attempts needed to solve the problem.</li>\n",
    "    <li> You might like to record these in an excel spreadsheet or similar</li>\n",
    "    <li> You might also chose to edit the code to automatically run 10 times and calculate the mean and standard deviation of the number of trials</li>\n",
    "    <li> <b> HINT:</b> Don't forget that if you put the results in a numpy array, numpy will calculate these for you if you ask nicely!</li>\n",
    "    <li>Then repeat, increasing the value of <em>num_vars</em> from 10 to 30 in steps of five </li>\n",
    "    <li> Plot your results as a curve of mean values (y-axis) vs num_varrs (x-axis) with error bars showing the standard deviation.</li>\n",
    "        </ul>\n",
    "    Can you explain what it is that makes this problem so easy?\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b69ef3-8c20-42a5-8e48-a2fc4e090f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e1ed83-167e-45ed-a935-83243d0aca06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"color:black\">\n",
    "    <h2> Activity 3: Adapting local search for a continuous problem</h2>\n",
    "    <h3> This is a stretch activity for the more confident coders.</h3>\n",
    "    <p>For continuous problems you will need to adapt your local search class.</p>\n",
    "    <p>This requires adapting more of the methods from the single member search class</p>\n",
    "    <p>I've suggested code that changes the <em>__init__</em> method \n",
    "            to initialise with appropriate continuous values,\n",
    "        and stores the number of samples to take from the neighbourhood each iteration, and whether to use gradient-based search or not.</p>\n",
    "    <p> So the first thing you need to do is over-ride the <em>select_and_move_from_openlist(self)</em> method\n",
    "        from your LocalSearch class so that it now accepts solutions that are as good \n",
    "        as <em>self.best_so_far</em> and not just improvements.</p>\n",
    "    <p> Then you need to over-ride and change the <em>run_search()</em> method so that it:</p>\n",
    "        <ol> \n",
    "            <li>generates a number of neighbours defined by self.sample_size</li>\n",
    "            <li> for each neighbour creates a set of changes (one for each decision) then adds those then truncates to the valid range of values (using function provided()\n",
    "            <li> If  <em> self.use_gradients</em> is <em>False</em> it generates the list of changes at random <br>\n",
    "                If it is <em>True</em> it calls <em>self.problem.get_gradient()</em> then multiplies the result by <em>self.learning_rate</em> to get the changes</li>\n",
    "            <li> after looking at all of the neighbours, if they were all worse than what we had already, the open_list will be empty, so you  you need to put the <em>working_candidate</em> back on the open list instead of the closed list.</li> \n",
    "        </ol>\n",
    "\n",
    " <h3> This version of the problem has a quality function that is the difference to  the target so it needs to be minimised</h3>   \n",
    "    <p>It also provides a <em>get_gradient() method</em> so you can try both approaches described in the lecture</p>   \n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e72ed-36f5-4bde-a15a-f3c053b44c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "class LocalSearchContinuous(SingleMemberSearch):\n",
    "    \"\"\"Implementation of local search for continuous problems.\n",
    "      Assumes the search mode is perturbative.\n",
    "      Extends single member search by doing explicit sampling of neighbourhood\n",
    "      and if not stopping if no improvment is  found in an iteration\n",
    "      Parameters\n",
    "      ---------\n",
    "      sample_size(int): \n",
    "          number of neighbours to generate each iteration\n",
    "          default 10\n",
    "      use_gradient(bool): \n",
    "          whether to use the gradient instead of random changes\n",
    "          if the problem supports it.\n",
    "          If set, assume sample_size is 1\n",
    "          default False\n",
    "      learning_rate(float)\n",
    "          multiplier for gradient if used\n",
    "          default 0.5\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"local search continuous\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        problem: Problem,\n",
    "        constructive: bool = False,\n",
    "        max_attempts: int = 50,\n",
    "        minimise:bool=True,\n",
    "        target_quality:float=1,\n",
    "        sample_size:int = 10,\n",
    "        use_gradient:bool=False,\n",
    "        learning_rate=0.5\n",
    "    ):   \n",
    "        super().__init__(problem, constructive=constructive,\n",
    "                       max_attempts=max_attempts,\n",
    "                       minimise=minimise,\n",
    "                       target_quality=target_quality)\n",
    "        print(f'self.target_quality is {self.target_quality}') \n",
    "        #reinitialise to random continuous values in right range\n",
    "        self.num_vars  = len(self.open_list[0].variable_values)        \n",
    "        for decision in range(self.num_vars):\n",
    "            self.open_list[0].variable_values[decision]= self.rand_in_range()\n",
    "        #re-evaluate\n",
    "        quality,_ = self.problem.evaluate(self.open_list[0].variable_values)\n",
    "        self.open_list[0].quality=quality    \n",
    "\n",
    "        #store the number of neighbours to examine each iteration \n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        #does the problem support calculation of gradients\n",
    "        self.use_gradient= use_gradient\n",
    "        self.learning_rate = learning_rate\n",
    "        if self.use_gradient:\n",
    "            try:\n",
    "                _=self.problem.get_gradient()\n",
    "                self.sample_size = 1\n",
    "            except:\n",
    "                self.use_gradient=False\n",
    "\n",
    "    def rand_in_range(self)->float:\n",
    "        \"\"\" generates a random number in the range\n",
    "        specified by the problem\n",
    "        \"\"\"\n",
    "        lowest_val = self.problem.value_set[0]\n",
    "        val_range = self.problem.value_set[1] - self.problem.value_set[0]\n",
    "        return np.random.random()*val_range +lowest_val\n",
    "    \n",
    "    def get_rand_normals_in_range(self)->list:\n",
    "        \"\"\" \n",
    "        generates random number form  normal distribtion\n",
    "        mean= midpoint of valid range for problem\n",
    "        sdev = 10% of valid range. for problem\n",
    "        \"\"\"\n",
    "        changes=[]\n",
    "        valrange = self.problem.value_set[1]-self.problem.value_set[0]\n",
    "        valmean =  (self.problem.value_set[1]+ self.problem.value_set[0])/2\n",
    "        for pos in range(self.num_vars):\n",
    "            randval= np.random.normal() *0.1*valrange + valmean\n",
    "            changes.append(randval)\n",
    "        return changes\n",
    "        \n",
    "    \n",
    "    \n",
    "    def truncate_to_range(self, val:float)->float:\n",
    "        \"\"\" truncates a val ot the valid range\n",
    "        defined by a problem\"\"\"\n",
    "        if val>self.problem.value_set[1]:\n",
    "            val = self.problem.value_set[1]\n",
    "        if val < self.problem.value_set[0]:\n",
    "            val = self.problem.value_set[0]\n",
    "        return val\n",
    "    \n",
    "    \n",
    "    def select_and_move_from_openlist(self) -> CandidateSolution:\n",
    "        \"\"\"Pops best thing from list, clears rest of list, then returns best thing\n",
    "        relies on the presence of self.best_so_far\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next\n",
    "           working candidate (solution) taken from open list\n",
    "           if it is an improvem ent\n",
    "        None\n",
    "           IF list is empty OR next thing is worse than best so far\n",
    "        \"\"\"\n",
    "        next_soln = CandidateSolution()\n",
    "\n",
    "        # edge cases\n",
    "        if len(self.open_list) == 0:\n",
    "            self.runlog += \"LS:empty open list\\n\"\n",
    "            return None\n",
    "\n",
    "        # get best child\n",
    "        best_index = 0\n",
    "        quality = self.open_list[0].quality\n",
    "        best_so_far: int = quality\n",
    "        ## your code to put the right value from the open list into next_soln\n",
    "        \n",
    "        self.runlog += (\n",
    "            f\"\\t best child quality {best_so_far},\\n\\t best so far {self.best_so_far}\\n\"\n",
    "        )\n",
    "        # clear the openlist\n",
    "        ## Your code here\n",
    "        # always accept first move\n",
    "        if self.trials == 1:\n",
    "            better: bool = True\n",
    "        # otherwise must be an improvement or at least as good (to keep search going)\n",
    "        #i.e best_so_far must be at least as good as self.best_so_far\n",
    "        \n",
    "        # your code to return best from open list \n",
    "        #or None if it doesn't improve on self.best_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eab913-601a-4048-820a-2acc354a01b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#search using option 1 from the lectures- adding gaussian n oise\n",
    "num_vars = 10\n",
    "continuous_onemax = OneMaxContinuous(N=num_vars)\n",
    "mysearch2 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0)\n",
    "    \n",
    "\n",
    "success = mysearch2.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch2.trials} attempts.\\n'\n",
    "           f'solution {mysearch2.result}\\n'\n",
    "           f' quality {mysearch2.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch2.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch2.runlog}'\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72077101-54e9-4089-97b5-4d1e4dc67e93",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Now search using the gradient information\n",
    "\n",
    "mysearch3 = LocalSearchContinuous( continuous_onemax,\n",
    "                        constructive = False,\n",
    "                        max_attempts= 500,\n",
    "                        minimise=True,\n",
    "                        target_quality=0.0,\n",
    "                        use_gradient=True,\n",
    "                        learning_rate=0.5)    \n",
    "\n",
    "success = mysearch3.run_search()\n",
    "if success:\n",
    "    print ( 'Local Search solved the problem '\n",
    "           f' after {mysearch3.trials} attempts.\\n'\n",
    "           f'solution {mysearch3.result}\\n'\n",
    "           f' quality {mysearch3.problem.evaluate(mysearch2.result)[0]}'\n",
    "          )\n",
    "else:\n",
    "    print(f'failed to solve the problem in {mysearch3.max_attempts} trials\\n'\n",
    "          f' runlog is:\\n {mysearch3.runlog}'\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa229165-f33a-4be0-8c96-393e244ad855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d40939-9924-46ee-b73c-8bbdd937e1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529b415-8528-4c76-abf9-b833471d33e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
