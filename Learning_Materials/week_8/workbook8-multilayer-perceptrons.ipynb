{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aims of this tutorial\n",
    "The aim of this tutorial is to provide hands-on experience of how Perceptrons can be combined into Neural Networks to learn complex models.   \n",
    "We will look at the key differences between the two algorithms and also consider how network architecture and training parameters affects the outcome.  \n",
    "To do that systematically we will implement a simple Machine Learning workflow - sometimes called a *pipeline* - to let us do fair, systematical and **automated** comparisons between algorithms.\n",
    "\n",
    "## Learning Objectives:\n",
    "1. Understand the key differences between the Neural Network and Perceptron algorithms:\n",
    "- Non-linear activation functions.\n",
    "- Using Backpropagation to update (learn) the weights.\n",
    "- configuring MLP with more than one output node when there are more than two different output labels (multi-class learning)\n",
    "2. Understand how different nodes learn different aspects of the problem.\n",
    "\n",
    "3. Understanding \n",
    "- that different **hyper-parameters** - for example network architectures and learning parameters  - can have significant impact on the ability to learn a good model from a data set,\n",
    "- how to perform **hyper-parameter tuning** to allow fair comparisons between different Machine Learning algorithms\n",
    "\n",
    "<div style= \"background:pink;colour:black\">\n",
    "    <h2>This is an assessed workbook.</h2>\n",
    "    <p>Instructions for: what you need to code and submit, and how marks will be allocated  will be made clear in the Activity descriptions below</p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "<img src=\"figures/ANN-2-Node.png\" style=\"float:right\" width= 500>\n",
    "\n",
    "As we have seen, Perceptrons are only capable of solving linearly separable problems.   \n",
    "To overcome this limitation, we can connect Perceptrons together into a network.  \n",
    "Each one becomes a Node in the network, and they are connected together into layers. \n",
    "\n",
    "In standard Artificial Neural Network (ANN) architecture there is one input,   one or more hidden layers, and one or more nodes in the output layer.  \n",
    "- Though the term *input layer* is a bit misleading, it doesn't actually do any computation, it is just the inputs to the network.\n",
    "- So, outputs of hidden layers become the inputs to subsequent hidden layers, or the final output layer. \n",
    "- Hidden nodes tend to learn different aspects of the problem space, building more complex decision boundaries and are therefore able to solve more complex problems.\n",
    "\n",
    "Note: \n",
    "- The number of nodes in the input layer must equal the number of inputs/features in the data. \n",
    "- One output node can discriminate between two classes (classification problems),  \n",
    "  or predict a value for one continuous variable (regression problems).  \n",
    "  If your data  has more than two classes (or variables to predict),  \n",
    "  the number of output nodes must equal the number of classes/regression variables. \n",
    "- The number of hidden layers and nodes in the layers is arbitrary, and selecting this architecture is part of building an ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training Algorithm  \n",
    "Similar to Perceptrons, ANN are trained in two 'phases'. \n",
    "- The forward pass, where data is input into the network to produce an output. \n",
    "- The backward pass, where the error in output is used to update the weights using Backpropagation and Gradient Descent.\n",
    "  - note that to calculate what the sum of  inputs was going *in* to a node we apply the *sigmoid derivative* to the signal coming *out* of that node \n",
    "\n",
    "<img src=\"figures/ann-pseudocode.png\" style=\"float:center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\"><h1> Part 1: Solving XOR</h1></div>\n",
    "As an introduction to the ANN algorithm, and to give you an intuition for how different nodes and layers in the network learn different aspects of the problem space, we are going to look at how a small network can solve the XOR problem.\n",
    "\n",
    "Running the code will train an ANN to solve the XOR problem and produces a visualisation to show how different nodes have learned different aspects of the problem to create a more complex decision boundary (in this case different logical functions).\n",
    "\n",
    "- You do not need to understand *how* the graphs/visualisations are produced.\n",
    "\n",
    "- You should try and understand *what* the graphs/visualisations output means.\n",
    "\n",
    "\n",
    "**Run the next  cells below** to import the libraries and define the function that plots the decision surface.\n",
    "- If the first cell reports an error trying to import VisualiseNN, make sure you have downloaded the file VisualiseNN.py and it is in the same directory as this notebook\n",
    "\n",
    "### The marked activity asks you to automate an experiment investigating how the ability to learn is affected by the *capacity* (potential complexity) of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics for manipulating and outputting arrays etc\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## MLP specific stuff\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import VisualiseNN as VisNN\n",
    "\n",
    "import workbook8_utils as wb8\n",
    "from W8_utils import plot_decision_surface_v1\n",
    "\n",
    "# useful sklearn functions for preprocessing data and sahowing results\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# the iris data\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"color:black\">\n",
    " <h2> Activity 1.1 Investigating repeatability as different sized networks learn to model the simple XOR problem</h2>\n",
    "    <p> We use the term <b> capacity</b> to describe the ability of a model to learn complicated decision boundaries.<br>\n",
    "        Another way of thinking about it is the model's <b>complexity</b> - the more complex a model, the greater its capacity to learn complicated things.<br>\n",
    "        For a multi-layer perceptron this is largely detyermined  by the number of hidden layers and the <i>width</i> of each - how many nodes they contain.<br>\n",
    "        This activity investigates this effect for the trivial xor problem, later you will try it for other datasets.</p>\n",
    "<p><b>Step 1:</b> Run the first cell below: it will try and learn the XOR problem and show you a plot of how the error rate changes over <i>time</i> measured in epochs. <br>\n",
    "    As there are only four cases, we do not have any test data for this problem - we are just looking at how reliably different sized networks can learn a simple problem.\n",
    "<ul>\n",
    "    <li> One epoch means that all the training data is shown to the system once and the weights are updated. </li>\n",
    "    <li> We know that <i>in theory</i> it should be able to learn XOR with 2 hidden nodes. <br>\n",
    "         But is there a difference between theory and what happens in practice? </li>\n",
    "    <li>Each time you run the cell it starts the whole process from a new set of random weights,<br>\n",
    "        so the error curve will be different and you might get different final accuracy scores.</li>\n",
    "    <li> Remember that Stochastic Gradient Descent is a form of local search - so what you are seeing here is the effect of the starting position!</li>\n",
    "</ul></p>\n",
    "<p> <b> Step 2:</b> Experiment with a few other values for the size of the hidden layer, doing a few runs for each to see what impact that has on whether  the network reliably learns a function that computes XOR</p>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell fits an MLP to the XOR problem once for a given network architecture \n",
    "#  The code illustrates how to measure accurcy and make a plot\n",
    "# You should use and adapt this code for  task 1.2\n",
    "\n",
    "#Step 1: Define the data set - in this case XOR with two inputs\n",
    "train_X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "xor_y = np.array([0, 1, 1, 0])\n",
    "train_y=xor_y\n",
    "\n",
    "# Step 2 define the size of the hidden layer-  at present just do one run for with two nodes in the hidden layer\n",
    "num_hidden_nodes = 2\n",
    "\n",
    "\n",
    "# Step 3 Create Multi-Layer Perceptron with one hidden layer of numHiddenNodes neurons with logistic activation\n",
    "# and Stochastic Gradient Descent (backprop)\n",
    "xorMLP = MLPClassifier(\n",
    "    hidden_layer_sizes=(num_hidden_nodes,),\n",
    "    max_iter=1000,\n",
    "    alpha=1e-4,\n",
    "    solver=\"sgd\",\n",
    "    verbose=0,\n",
    "    learning_rate_init=0.1,\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "# Step 4: fit the model  it to the data\n",
    "xorMLP.fit(train_X, train_y)\n",
    "\n",
    "#Step 5 measure and print the accuracy\n",
    "# this also shows you how to access the point at which training stopped\n",
    "training_accuracy = 100 * xorMLP.score(train_X, train_y)\n",
    "print(f\"Training set accuracy: {training_accuracy}% after {xorMLP.n_iter_} iterations\")\n",
    "\n",
    "#Step 6 produce a plot of training loss (error) vs number of epochs\n",
    "fig,ax= plt.subplots(nrows=1,ncols=1)\n",
    "ax.plot(xorMLP.loss_curve_)\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel(\"training epochs\")\n",
    "ax.set_ylabel(\"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\" style=\"color:black\">\n",
    " <h2> Activity 1.2 (Assessed) <br>Automating the investigation of the effect of model <i>capacity</i> on learning behaviour</h2>\n",
    "    <h3> 20 Marks:</h3>\n",
    "    <ul>\n",
    "        <li>0 marks if the code cell with the function <code>make_reliability_plot()</code> contains any text outside the function body</li>\n",
    "        <li> 0 marks if your code does not return the fig and axes objects as required</li> \n",
    "    <li>10 marks for producing a matplotlib figure containing two matplotlib ax objects with titles and labels as specified below,<br>\n",
    "    and returning the objects (i.e. a figure and an array of axes) </li>\n",
    "    <li> 5 marks each if the contents of the plots match the <i>reference version</i>.<br> This means you <b>must</b> set the <i>random_state</i> hyperparameter for each run as described below</li>\n",
    "    </ul>  \n",
    "<p></p>\n",
    "\n",
    "<h3>Task definition:</h3> Complete the function in  the  cell below to <i>automate</i> the process of investigating the effect of the model <i>capacity</i> (as controlled by <i>hidden_layer_sizes</i> hyper-parameter) for a MLP with a single layer of hidden nodes on:\n",
    "<ul> <li>the <i>reliability</i> - as measured by the <i> success rate</i> i.e. the proportion of runs that achieve 100% training accuracy</li>\n",
    "<li>  the <i> efficiency</i> - the mean number of training epochs per successful run.<br>\n",
    "    Note that to avoid <i>divide-by-zero</i> problems you should check if no runs are successful for a given value and report a value of 1000 in that case.  </li>\n",
    "    </ul>\n",
    "<p>What should be in the plots?</p>\n",
    "<ul>\n",
    "    <li> You must return two objects <i>fig</i> and <i>axs</i> produced by a call to <code>plt.subplots(1,2)</code></li>\n",
    "    <li> The left hand plot should have a title \"Reliability\", y-axis label \"Success Rate\" and x-axis label \"Hidden Layer Width\".</li>\n",
    "    <li> The right hand plot should have a title \"Efficiency\", y-axis label \"Mean epochs\" and x-axis label \"Hidden Layer Width\".</li>\n",
    "    <li> In both cases the width of the single hidden layer should cover the range 1,10 (inclusive) in steps of 1</li>\n",
    "    <li> Each plot should contain an appropriate line illustrating the results of the experiment</li> \n",
    "</ul>    \n",
    "<h3>How to go about the task</h3> \n",
    "    <p> In several of the stages below you will be adapting code from activity 1.1 and 'steps' refer to comments  and code snippets in that code cell.</p>\n",
    "<ol>\n",
    "    <li> Declare a list <code>hidden_layer_width</code> holding the values 1 to 10 (inclusive) defining the model size.</li>\n",
    "    <li> Declare a 1-d numpy array filled with zeros  called <code>successes</code> to hold the number of successful runs for the different model sizes.</li>\n",
    "    <li> Declare a 2-D numpy array filled with zeros of shape (10,10) called <code>epochs</code> \n",
    "    <li> Create two nested loops: one over all the values for a variable <code>h_nodes</code> from the list <code>hidden_layer_width</code> <br> and the other for a variable <code>repetition</code> between 0 and 9 (i.e. doing 10 repetitions).</li>\n",
    "    <li> Inside those loops \n",
    "        <ol>\n",
    "        <li>Copy and edit code from  step 3 from the first cell to create an MLP with one hidden layer containing the <i>h_nodes</i> nodes. <br><b>Make sure</b> that in the call  you set the parameter <i>random_state</i> to be the run index so the results are the same as mine.  </li>\n",
    "        <li>Copy and edit code from step 4 to  <i>fit</i> the model to the training data, </li>\n",
    "        <li>Copy and edit code from Step 5 to measure it's accuracy</li>\n",
    "            <li> If the accuracy is 100%:<ul>\n",
    "                <li><i>increment</i> the count  in  cell  <code>successes[hnodes]</code></li>\n",
    "            <li> store the number of epochs taken in the cell of the array <code>epochs[h_nodes][repetition]</code>.</li>\n",
    "            </ul>\n",
    "        </ol>\n",
    "    <li> Create a new array with one entry for each number of hidden nodes tested, that contains either:\n",
    "        <ul>\n",
    "            <li> 1000 if no runs got 100% accuracy for that network size</li>\n",
    "            <li> The mean number of epochs taken per successful run for that network size</li>\n",
    "        </ul>\n",
    "    <li>Copy and edit the code from step 6 in Activity 1.1 to make a figure contain two plots side-by-side as described in the task definition, set appropriate axis labels and title labels, and return the fig and axs objects </li>\n",
    "</ol>\n",
    "    <h3> Checklist before submission</h3>\n",
    "    <ul>\n",
    "    <li> The second cell below will let you test your code works before submission. </li>\n",
    "        <li> The marking system will reject your submission if there is any text or code  in the second cell that it outside inside the function definition.</li>\n",
    "        <li> Your function <b>must</b> return two things: the fig object, and the axs object (which should be an array of axes with shape (1,2).</li>\n",
    "     </ul>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_xor_reliability_plot(train_x,train_y):\n",
    "    \"\"\" Insert code below to  complete this cell according to the instructions in the activity descriptor.\n",
    "    Finally it should return the fig and axs objects of the plots created.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_x (numpy.ndarray): feature values \n",
    "    train_y  (numpy array): labels\n",
    "    use these for training and evalaution of this simple problem\n",
    "    \"\"\"\n",
    "    \n",
    "    #return fig,axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use this to test your code\n",
    "make_xor_reliability_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\">\n",
    "    <h2>Activity 1.3: Visualising what the network is doing</h2>\n",
    "<p>The cell below shows  an example MLP with 4 hidden layer nodes being created and fitted to the xor problem follow by some  simple visualisations.</p>\n",
    "<p>The top plot shows the output of the final node for different inputs.\n",
    "    <ul> <li>In this case we only have the four inputs marked by circles.</li>\n",
    "        <li> In use, we would apply a threshold of 0.5 to decide whether the output of the network was 1 or 0 <br>\n",
    "            So the orange lines represent the decision boundaries.</li></ul\n",
    "    \n",
    "<p> The bottom plot shows a visualisation of the network structure and weights: \n",
    "   <ul>\n",
    "        <li> The line thickness represents the magnitude of the weight</li>\n",
    "       <li> The line colour indicates the sign of the weight:<br>\n",
    "           Blue lines are <b>negative weights</b>, so signals down these connections will  suppress the output of the cell they lead to. <br>\n",
    "           Red lines are <b> positive weights</b>- so signals down these connections will  stimulate the node they lead to.</li>\n",
    "    </ul>     \n",
    "        <h4> A thought experiment for you</h4>\n",
    "        <p>What this plotting library does not show is the bias nodes for each layer and the strength of the bias connections.<br>\n",
    "        Based on the:\n",
    "        <ul>\n",
    "        <li>values of the weights, and</li>\n",
    "        <li>the description in week 7 of how you can create an XOR gate from a combinations of  AND,OR,NAND,and NOR,</li>\n",
    "        <li> can you figure out what the hidden bias weights are for the hidden nodes?</li>\n",
    "        </ul> \n",
    "        </p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xorMLP= MLPClassifier(\n",
    "    hidden_layer_sizes=(4,), max_iter=1000,\n",
    "    alpha=1e-4, solver=\"sgd\",\n",
    "    learning_rate_init=0.1,   random_state=5\n",
    ")\n",
    "\n",
    "# Step 4: fit the model  it to the data\n",
    "xorMLP.fit(train_X, train_y)\n",
    "\n",
    "fig3,ax3=plt.subplots()\n",
    "plot_decision_surface_v1(ax=ax3,model=xorMLP,X= train_X, y=train_y)\n",
    "\n",
    "\n",
    "# network_structure = np.hstack(([train_X.shape[1]], np.asarray(myMLP.hidden_layer_sizes), [train_y.shape[0]]))\n",
    "network_structure = np.hstack((2, np.asarray(xorMLP.hidden_layer_sizes), 1))\n",
    "# Draw the Neural Network with weights\n",
    "network = VisNN.DrawNN(network_structure, xorMLP.coefs_)\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\"><h1> Part 2: Using MLP for multiclass problems:  Iris data</h1></div>\n",
    "<img src=\"./figures/cascading.png\" style=\"float:right\">\n",
    "\n",
    "So far we have used multilayer perceptrons for learning binary (two-class) problems.  \n",
    "Last week you should have discussed how you could solve a multi-class problem,  \n",
    "by 'cascading' binary classifiers. \n",
    "This is shown in the image for a three class problem.  \n",
    "Here the diamonds represent classifiers, each doing a \"this class or not\" decision.\n",
    "\n",
    "\n",
    "In this part we will introduce a different idea, which is to use a  parallel classifier using softmax and one-hot encoding.\n",
    "\n",
    "Not only is this simpler to manage, it  has the benefit that the classifiers can all share the feature creation done in previous layers\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this cell to load the data\n",
    "\n",
    "\n",
    "iris_x, iris_y = load_iris(return_X_y=True)\n",
    "feature_names = [\"sepal width\", \"sepal_length\", \"petal_width\", \"petal_length\"]\n",
    "iris_labels = np.array((\"setosa\", \"versicolor\", \"virginica\"))\n",
    "# show what the labels look like\n",
    "print(iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming our label data to a format for training a MLP with three output nodes\n",
    "As you can see when you run the cell above, the labels is a 1-D array with labels of 0, 1, or 2.  \n",
    "This is fine for models like nearest neighbours, rule sets or decision trees.  \n",
    "However, (crudely speaking) the output from a neuron tends to be *off* (0) or *on*(1).  \n",
    "So if we want our network to make a choice of three predictions, then we need a node for each class.\n",
    "\n",
    "So there are two changes we make:\n",
    "1. We configure the network to have three output nodes  and use 'softmax' ('winner-takes-all') activation.  \n",
    "    i.e. Each node outputs a value, and we take as our final output the class whose node has the highest output signal\n",
    "2. We convert our labels tell the network what *each of the nodes* should ideally output for each training example.  \n",
    "   In other words:\n",
    "   - if the label is 0 the then output should be [1,0,0],  \n",
    "   - if the label is 1 it should be [0,1,0], and \n",
    "   - if it is 2 the output should be [0,0,1].\n",
    "\n",
    "Sklearn comes with a module sklearn.preprocessing.onehotencoder() to do this,   \n",
    "but the cell below does it explicitly to illustrate what is going on. \n",
    "\n",
    "I've made it generic so that you can easily reuse it for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this cell to create the one-hot version of the labels  we need for our MLP\n",
    "numcases = len(iris_y)\n",
    "print(f\"there are {numcases} training examples\")\n",
    "thelabels = np.unique(iris_y)\n",
    "numlabels = len(thelabels)\n",
    "print(f\"there are {numlabels} labels: {thelabels}\")\n",
    "\n",
    "# make a 2d array with numcases rows. and numlabels columns\n",
    "iris_y_onehot = np.zeros((numcases, numlabels))\n",
    "\n",
    "\n",
    "# Now loop through the rows of the new array setting the appropriate column value to 1\n",
    "for row in range(numcases):\n",
    "    label = iris_y[row]\n",
    "    iris_y_onehot[row][label] = 1\n",
    "\n",
    "print(\"This is what  rows 45-55 of the one-hot version of the labels look like\")\n",
    "print(iris_y_onehot[44:55, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data\n",
    "\n",
    "As for most machine learning algorithms, the problem becomes much easier if we don't have to worry about features having different ranges.\n",
    "\n",
    "A **MinMaxScaler** simply does this independently for each feature (column) *i* in the  data array *x*:\n",
    "- finds the min and max values for feature *i*: $min_i$ and $max_i$\n",
    "- scales each column to a standard range by\n",
    "  - subtracting the minimum column value $min_i$   so that the values now lie between 0 and ($max_i - min_i$)\n",
    "  - dividing by the range **so that the values lie between 0 and 1**  \n",
    "  $ x[row][i] = \\frac {x[row][i] - min_i} {max_i - min_i}$\n",
    "  \n",
    "We can do this in code, but the next cell uses a sklearn function to do it for us\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "iris_x = MinMaxScaler().fit_transform(iris_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data into a training and a test set\n",
    "\n",
    "As you can see from the output of the cells above, the iris data has groups all the classes i.e. rows 0-49 are 'iris-setosa', 50-99 are 'iris versicolor'. and rows 100-149 are 'iris-virginica'.\n",
    "\n",
    "So if we want to train our network  and then estimate how well it will do on new data, we need to split this into a training and test set.  \n",
    "Again, we could do this manually:\n",
    "- first shuffling the rows so that we got a mixture of classes, \n",
    "- then taking the first part of the data for training and the second for testing.\n",
    "\n",
    "If the data are not so well organised, or the numbers of examples of different classes are not roughly equal, then that code gets trickier.  \n",
    "So the cell below shows how to do this using a method from sklearn.   \n",
    "The parameters are, in order:\n",
    "- the feature values (irisx)\n",
    "- the onehot-encoded set of labels (iris_y_onehot)\n",
    "- what proportion of our data we holdback from training, so we can use it for test. We'll use 1/3rd ( test_size=0.33)\n",
    "- the array holding the labels that we want to be evenly represented in both our training and test sets. (stratify=irisy_onehot)\n",
    "\n",
    "This function returns the four different arrays - train and test, x and y.  \n",
    "Noe that this function also works if your data is not one-hot encoded - it figures that out for itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this cell to make the train and test data\n",
    "iris_train_x, iris_test_x, iris_train_y, iris_test_y = train_test_split(\n",
    "    iris_x, iris_y_onehot, test_size=0.33, stratify=iris_y_onehot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style = \"color:black\">\n",
    "    <h2>Activity 2.1 Training a MLP to learn the iris classification problem.</h2>\n",
    "<ol>\n",
    "    <li> Start by using the  settings for the MLPClassifier that we had before and just change the size of the hidden layer to five or ten </li>\n",
    "   <ul> \n",
    "       <li> You will probably see that the training stops making improvements before the problem has been fully learned.</li>\n",
    "       <li> This is an example of the backpropagation getting 'stuck' in a **local optimum** . </li>\n",
    "        <li> It happens becuase the basic 'stochastic gradient descent' algorithm *'sgd'* is a local search method with only crude methods for getting out of 'traps'.</li> \n",
    "       <li> Try changing the solver to 'adam' and see if this gives better performance. </li>\n",
    "    </ul>\n",
    "    <p><b>Remember</b> to run a few times with each setting because this is a randomised algorithm and the random set of initial weights makes a huge difference.  </p>\n",
    "    <p><b>Question</b> What do you understand by <it>\"better\"</it> performance?</p><p></p>\n",
    "\n",
    "<li> Now try adding a second hidden layer - for example by changing that parameter in the constructor to <it>hidden_layer_sizes=(3,3)</it>.<br>  \n",
    "<li> Experiment with a few runs of each configuration to see if the network learns the problem more reliably with one hidden layer of 10 nodes or 2 layers of 5 nodes.</li>\n",
    "</ol>  \n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an MLP object-  you will want to change the number of hidden nodes\n",
    "irisMLP = MLPClassifier(\n",
    "    hidden_layer_sizes=(5,),\n",
    "    max_iter=1000,\n",
    "    alpha=1e-4,\n",
    "    solver=\"adam\",\n",
    "    verbose=0,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the data\n",
    "irisMLP.fit(iris_train_x, iris_train_y)\n",
    "print(\"number of output nodes = \" + str(irisMLP.n_outputs_))\n",
    "\n",
    "# Query the model for its training history and accuracy and display them\n",
    "lossplot = plt.plot(irisMLP.loss_curve_)\n",
    "plt.xlabel(\"training epochs\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "# report how well it does on the training set\n",
    "training_accuracy = 100 * irisMLP.score(iris_train_x, iris_train_y)\n",
    "print(f\"Training set accuracy: {training_accuracy} %\")\n",
    "\n",
    "\n",
    "# now how good is our network at predicting data it has never seen before\n",
    "test_accuracy = 100 * irisMLP.score(iris_test_x, iris_test_y)\n",
    "print(f\"Estimated (Test set) accuracy: {test_accuracy}%\")\n",
    "\n",
    "# this bit of code prints a simple confusion matrix showing how the predicted labels correspond to the 'real' ones\n",
    "predictions = irisMLP.predict(iris_test_x)\n",
    "confusion = np.zeros((3, 3))\n",
    "for row in range(predictions.shape[0]):\n",
    "    actual = np.argmax(iris_test_y[row])\n",
    "    predicted = np.argmax(predictions[row])\n",
    "    confusion[actual][predicted] += 1\n",
    "\n",
    "print(\"\\nPredicted->   Setosa  Versicolor  Virginica\")\n",
    "print(\"Actual \")\n",
    "for i in range(3):\n",
    "    print(\n",
    "        f\"{iris_labels[i]:<10}       {confusion[i][0]:2.0f}       {confusion[i][1]:2.0f}       {confusion[i][2]:2.0f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"color:black\"><h2> Activity 2.2 Discussion</h2>\n",
    "Try to come up with answers to these questions. (these are the sorts of things you might be asked in an exam)\n",
    "<ol>\n",
    "    <li>Why is the test accuracy sometimes much lower than the training accuracy?</li>\n",
    "     <li>Why is it sometimes less reliable train a network with multiple hidden layers when learning the iris data?  <br>\n",
    "Hint: how many connections are you trying to learn?  <br>How much data have you got?</li>\n",
    "    </ol></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-warning\" style=\"color:black\">\n",
    "    <h2>Activity 2.3 Assessed: <br>\n",
    "    Creating a test workflow to fairly assess three different supervised learning algorithms on a dataset</h2>\n",
    "    <h3> 80 marks</h3>\n",
    "    <h4> Task Description: </h4>\n",
    "    <p> Complete the functions in the skeleton class (obeying any instructions in the method docstrings about types and names of variables) below to create a class with the following functionality listed below:\n",
    "        <ol>\n",
    "            <li> The <code>__init__</code> method should read in and store a set of input examples and labels<br>\n",
    "            from two files whose names are provided at run-time <b>(10 marks)</b></li>\n",
    "            <li> The <code>preprocess()</code> method should perform any preprocessing of the stored input examples needed to ensure the comparison between algorithms is fair.<b>(10 marks)</b></li>\n",
    "            <li> The <code>make_label_encoders</code> method should check whether there are more than two labels present in <i>data_y</i>,<br>\n",
    "    and if so make any different encodings of the labels needed for different classifiers.<b>(10 marks)</b></li>\n",
    "            <li> The <code>run_comparison()</code> method should do a fair comparison of the classifier versions of k-Nearest Neighbour, DecisionTree and MultilayerPerceptron algorithms, and store the best accuracy for each.<br>\n",
    "            <i>Fair</i> means doing hyper-parameter tuning for the combinations of values given below and storing each trained model.<b>(3 x 10 marks)</b><br>\n",
    "            Models should be saved by appending to a list held as the value in a dictionary <code>self.stored_model</code>(see below for details).<br>You are encouraged to use the scikit-learn versions of all three algorithms as they have common interfaces which will make your coding easier.</li>\n",
    "            <li> The best comparison result for each algorithm, and the location of the stored model, should be stored by creating and then adapting dictionaries called <br>\n",
    "            <code>self.best_model_index:dict = {\"kNN\":0, \"DecisionTree\":0 and \"MLP\":0}</code> and <br>\n",
    "             <code>self.best_accuracy:dict = {\"kNN\":0, \"DecisionTree\":0 and \"MLP\":0}</code> <b>(10 marks)</b>\n",
    "</li>\n",
    "    <li> The <code>report_best()</code> method should report the best performing model, in the format specified.<b>(10 marks)</b></li>\n",
    "    </ol>\n",
    "    <p> For the KNearestNeighbor algorithm you should try K values from the set {1,3,5,7,9}</p>\n",
    "    <p> For DecisionTreeClassifer you should try every combination of <br>\n",
    "    <i>max_depth</i> from the set {1,3,5} with<br>\n",
    "    <i>min_split</i> from the set {2,5,10} and <br>\n",
    "    <i> min_samples_leaf</i> from the set {1,5,10}.</p>\n",
    "    <p> For MultiLayerPerceptron you should try every combination of <br>\n",
    "    <i>first hidden layer width</i> from the set {2,5,10} with<br>\n",
    "    <i>second hidden layer width</i> from the set {0,2,5} and<br>\n",
    "    <i> activation</i> from the set {\"logistic\",\"relu\"}.</p>\n",
    "    <h4> How to begin?</h4>\n",
    "    <p>This task builds heavily on  the code in this notebook, and that you wrote in worksheet 6 activity 4.\n",
    "    So make sure you have completed that activity before attempting this task.</p>\n",
    "    <h4> Things you must do so we can mark your code and provide feedback  automatically</h4>\n",
    "    <ul> \n",
    "    <li> The examples and labels should be stored in arrays <code>data_x</code> and <code>data_y</code> </li>\n",
    "    <li> The constructor should  create a dictionary to hold all the stored models<br> <code> self.stored_models:dict={\"KNN\":[],\"DecisionTree\":[],\"MLP\":[]}</code> </li>\n",
    "    <li> As your code creates and fits models of different types they should be appended to the relevant list in the <i>stored_models</i> dictionary.<br>\n",
    "        i.e., each different MLP model gets appended to the list <i>self.stored_models[\"MLP\"]</i> after the call to <i>fit()</i></li> \n",
    "    <li>It probably makes sense to check and update the values held in <i>self.best_accuracy</i> and <i>self.best_model_index</i> as you test each model</li>\n",
    "    <li> It is acceptable to do only one run of each algorithm-hyperparameter combination</li>\n",
    "    <li> Any code that takes a <i>random_state</i> parameter should be given the value 12345</li>\n",
    "    </ul>\n",
    "    <div style=\"background:lightgreen\"><h2> Don't over-think this!</h2><ul> \n",
    "        <li>You have most of the code snippets you need,</li>\n",
    "        <li>and the hyper-parameter tuning is mostly a case of nested loops to run through combinations of values</li>\n",
    "        <li> and from the search topic you should be used to keeping track of 'best-so-far' as you go through options</li></ul></div>\n",
    "    <h4>Remember the marking system will not accept code cells if you have anything outside your class definition</h4>\n",
    "    <h4> The point is that your code should work for different datasets - so don't hard code things about the data</h4> \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLComparisonWorkflow:\n",
    "    \"\"\" class to implement a basic comparison of supervised learning algorithms on a dataset \"\"\" \n",
    "    \n",
    "    def __init__(self,datafilename:str,labelfilename:str):\n",
    "        \"\"\" Method to load the feature data and labels from files with given names,\n",
    "        and store them  in arrays called data_x and data_y.\n",
    "        \n",
    "        You may assume that the features in the input examples are all continuous variables\n",
    "        and that the labels are categorical, encoded by integers.\n",
    "        The two files should have the same number of rows.\n",
    "        Each row corresponding to the feature values and label\n",
    "        for a specific training item.\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "    def preprocess(self):\n",
    "        \"\"\" Method to \n",
    "           - apply the preprocessing you think suitable to the data\n",
    "           - separate it into train and test splits (using a 70:30 division)\n",
    "           Remember to set random_state = 12345 if you ue train_test_split()\n",
    "        \"\"\"\n",
    "        self.stored_models:dict={\"KNN\":[],\"DecisionTree\":[],\"MLP\":[]}\n",
    "                                 \n",
    "                                 \n",
    "                                 \n",
    "    def make_label_encodings(self):\n",
    "        \"\"\" Method to make one-hot encodings if the data has more than two labels.\n",
    "        Note you will probably need to keep the original label array for some algorithms\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def run_comparison(self):\n",
    "        \"\"\" Method to perform a fair comparison of three supervised machoinbe learning algorithms.\n",
    "        Should be extendable to include more algorithms later.\n",
    "        \n",
    "        For each of the algorithms KNearest Neighbour, DecisionTreeClassifer and MultiLayerPerceptron\n",
    "        - Applies hyper-parameter tuning to find the best combination of relvant values for the algorithm\n",
    "         -- creating and fitting model for each combination, \n",
    "            then storing it in the relevant list in a dictionary called self.stored_models\n",
    "            which has the algorithm names as the keys and  lists of stored models as the values\n",
    "         -- measuring the accuracy of each model on the test set\n",
    "         -- keeping track of the best performing model for each algorithm, and its index in the relevant listso it can be retrieved.\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def report_best(self) :\n",
    "        \"\"\"\n",
    "        Method to analyse results.\n",
    "        Returns\n",
    "        -------\n",
    "        accuracy (float) - the accurcy of the best performing model\n",
    "        algorithm (str) - one of \"KNN\",\"DecisionTree\" or \"MLP\"\n",
    "        model (fitted model of relvant type)- the actual fitted model to be interrogated by marking code.\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test your code before submission\n",
    "#dump iris data to file\n",
    "iris_x, iris_y = load_iris(return_X_y=True)\n",
    "np.savetxt(\"irisx.csv\", iris_x, delimiter=\",\")\n",
    "np.savetxt(\"irisy.csv\", iris_y, delimiter=\",\")\n",
    "\n",
    "#run your code\n",
    "mycomparison = MLComparisonWorkflow(datafilename=\"irisx.csv\", labelfilename= \"irisy.csv\")\n",
    "\n",
    "mycomparison.preprocess()\n",
    "\n",
    "mycomparison.make_label_encodings()\n",
    "\n",
    "mycomparison.run_comparison()\n",
    "\n",
    "#sanity check- loop through stored models making sure there are the right number\n",
    "assert len (mycomparison.stored_models[\"KNN\"]) == 5,\"wrong number of stored knn models\"\n",
    "assert len (mycomparison.stored_models[\"DecisionTree\"]) == 27,\"wrong number of stored DT models\"\n",
    "assert len (mycomparison.stored_models[\"MLP\"]) == 18,\"wrong number of stored MLP models\"\n",
    "\n",
    "# now print findings from the workflow\n",
    "accuracy, algname, index = mycomparison.report_best()\n",
    "print( f' Best test accuracy is {accuracy}, '\n",
    "      f' created by the {algname} algorithm'\n",
    "      f'with these hyper-parameters:'\n",
    "     )\n",
    "bestmodel =  mycomparison.stored_models[algname][index]\n",
    "for key,val in model.__dict__.items():\n",
    "    print(f'{key} : {val}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" style=\"color:black\"><h1> Part 3: Learning to recognise hand-written digits:  MNIST</h1></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style= \"color:black\"><h2>Activity 3.1: Loading and visualising the data</h2>\n",
    "<ol>\n",
    "    <li>Edit the first cell to give the right path depending on whether you are using csctcloud or your own installation</li>\n",
    "    <li> Then run the second cell to visualise the data.</li>\n",
    "    </ol>\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find directory holding data cepending on what machine you are on\n",
    "import socket\n",
    "if (socket.gethostname()=='csctcloud'): #on csctcloud\n",
    "    datapath=\"/home/common/datasets\"\n",
    "else:  #you will need to change this if you are using data on your local machine\n",
    "    datapath=\"/Users/j4-smith/GitHub/common/datasets/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Only  Run this cell if you are using the ccstcloud server\n",
    "# example code to run on the server using a copy of the data that I have already downloaded and made available.\n",
    "# label is column 0\n",
    "# pixel values are from 0-255 so need to be scaled to 0-1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test = np.genfromtxt(datapath +\"mnist/mnist_test.csv\", delimiter=\",\")\n",
    "X_test = test[1:, 1:785] / 255\n",
    "y_test = test[1:, 0]\n",
    "\n",
    "train = np.genfromtxt(datapath +\"mnist/mnist_train.csv\", delimiter=\",\")\n",
    "X_train = train[1:, 1:785] / 255\n",
    "y_train = train[1:, 0]\n",
    "\n",
    "print(\n",
    "    f\"X_train has {X_train.shape[0]} rows and {X_train.shape[1]} columns, y_train has {y_train.shape} entries,\\nX_test has shape {X_test.shape} y_test has {len(y_test)} entries.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell  shows us some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display ten random images from each class\n",
    "print(\n",
    "    f\"The test data has {X_test.shape[0]} images, each described as a {X_test.shape[1]} features (pixel values)\"\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for label in range(10):\n",
    "    imagesForLabel = np.empty((0, 784))\n",
    "    examples = 0\n",
    "    next = 0\n",
    "    while examples < 5:\n",
    "        if int(y_test[next]) == int(label):\n",
    "            imagesForLabel = np.vstack((imagesForLabel, X_test[next]))\n",
    "            examples += 1\n",
    "        next += 1\n",
    "    for col in range(5):\n",
    "        exampleplot = plt.subplot(10, 5, (label * 5 + col + 1))\n",
    "        exampleplot.imshow(imagesForLabel[col].reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-warning\" style = \"color:black\"> <h2>Activity 3.2 : Visualising what features the hidden layers learn to respond to.</h2> \n",
    "    <p>We will now configure a multilayer perceptron  and training it with all 60,000 images from the standard MNIST training set.</p>\n",
    "\n",
    "<p>The idea for you to learn here, is that each hidden node is effectively acting as a feature detector. <br>\n",
    "  <ol>\n",
    "      <li> So let's consider just one hidden layer node: \n",
    "          <ul>\n",
    "           <li> and a simple pattern where the weights from pixels in the top left and bottom right quadrant are all +1, </li>\n",
    "            <li> and the weights from pixels in the top-right and bottom-left quadrants are all -1.</li>\n",
    "          </ul> \n",
    "      </li>\n",
    "      <li> Now consider an input image that has some constant value for every pixel (feature) - i.e. is all the same colour. \n",
    "          <ul>\n",
    "             <li> When these inputs to the node  are multiplied by their weights and summed, they will cancel each other.</li>\n",
    "             <li> So the <b> weighted sum </b> will be zero,</li>\n",
    "            <li> and the <b>output</b> of the node  will be sigmoid(0) = 0.5, which we class as 0</li>\n",
    "          </ul>\n",
    "      </li>\n",
    "     <li> Next consider an the image  of a simple 'chequer' pattern with  white (255) in the top-left and bottom-right quadrants,  \n",
    "  and black (0)  in the other two.\n",
    "         <ul>\n",
    "          <li>In this case  the pattern of  pixel intensities (features) in the image  maches match the pattern in the weights.</li>\n",
    "             <li>So then the weighted sum will be at its maximum, and the <b>node will output +1.<b></li>\n",
    "         </ul>\n",
    "             </ol>\n",
    "         <p>So we can consider our hidden node is acting as a 'feature detector' for the checker pattern.<br>\n",
    "             And in general <b>each</b> hidden node is a feature detector that  <b>learns</b> to recognise useful patterns during training.<br>\n",
    "             And hidden nodes in the 2nd,3rd,...nth layers build complex features out of those recognised by the layer before.</p>\n",
    "<p>\n",
    "  <b>Run</b> the next set of cells to:<ul>\n",
    "<li> Set up and train the network with 16 nodes (a number chosen so we can visualise them neatly in a grid). </li>\n",
    "         <li> Then output the pattern  weights from each of the nodes as an image.</li></ul>\n",
    "      </p></div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> In year 2, the Machine Learning module will explain how this concept of feature detectors has been extended  in Deep Convolutional Networks. <br>\n",
    "In these features (called 'filters') can be a smaller size than the image and a process of Convolution (rather than straighforward multiplying) lets them detect small local features anywhere in the image.<br>  Convolutional Neural Networks have completely revolutionised the field of image processing and AI for visual tasks.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up and train network\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "numHiddenNodes = 16\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(numHiddenNodes), early_stopping=True, verbose=1)\n",
    "\n",
    "# this example won't converge because of CI's time constraints, so we catch the\n",
    "# warning and are ignore it here\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set accuracy: {100*mlp.score(X_train, y_train)}%\")\n",
    "print(f\"Test set accuracy: {100*mlp.score(X_test, y_test)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the next cell to  visualise what the hidden nodes are responding to - you don't need to go through the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the weights from the input nodes to the first hidden layer\n",
    "coef = mlp.coefs_.copy()[0].T\n",
    "\n",
    "print(coef[0].max(), coef[0].min())\n",
    "\n",
    "# find endpoints to use for scaling colour range\n",
    "scalemax = coef.max()  # *0.75\n",
    "scalemin = coef.min()  # *0.75\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "numRows = 4\n",
    "numCols = 5\n",
    "\n",
    "for i in range(numHiddenNodes):\n",
    "    l1_plot = plt.subplot(numRows, numCols, i + 1)\n",
    "    l1_plot.imshow(\n",
    "        coef[i].reshape(28, 28), cmap=plt.cm.seismic, vmin=scalemin, vmax=scalemax\n",
    "    )\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    # l1_plot.set_xlabel('Hidden Node %i' % i)\n",
    "title = \"Learned weights from pixels to each hidden node which correspond to patterns the nodes have been trained to respond to.\\n\"\n",
    "title = (\n",
    "    title\n",
    "    + \"Looking at a hidden node:\\n    Parts of the image where a node has weights coloured white (0.0) are ignored.\\n\"\n",
    ")\n",
    "title = (\n",
    "    title\n",
    "    + \"    Blue [red] indicates negative [positive] weights: signals from these pixels suppress [stimulate] the node.\\n\"\n",
    ")\n",
    "title = (\n",
    "    title\n",
    "    + \"    so a sensitive (red) areas might have a blue border to mark whereit must have an edge\"\n",
    ")\n",
    "title = (\n",
    "    title\n",
    "    + \"\\n    Remember that each node could have positive or negative effect on each output node\"\n",
    ")\n",
    "\n",
    "_ = plt.suptitle(title, x=0.15, horizontalalignment=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\"><h2> Activity 3.3: Discussion / Thought exercises </h2>\n",
    "Iris is a simple problems with only 4 features and three classes.\n",
    "\n",
    "MNIST is a much more complicated problem with 784 features and ten classes - some of which (e.g. 4s and sevens) can be drawn in completely different ways.\n",
    "<p>\n",
    "    <b>Questions:</b><ol>\n",
    "    <li>So how come the accuracy is roughly the same on these two problems?</li>\n",
    "    <li> The MNIST MLP you just trained and visualised has 10 nodes in its output layer, each receving numHiddenNodes (16) input signals. <br>\n",
    "        This means the hidden layer is effectively learning to  reducing a 784-Dimensional problems to a 16-dimensional one!<br>\n",
    "        How cool is that?<br>\n",
    "        From your observations of the visualisations, does it look like we even need 16 hidden nodes / dimensions/features?</li>\n",
    "    </ol></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\"> <h2>Activity 3.4: examining the effect of having less data.</h2>\n",
    "<p>The code in the cell below has a loop which trains a newtwork with different amounts of training data, and reports the training and test accuracy for each run. </p>\n",
    "<p>  Run the cell below and make note of the train and test accuracy for each different sized training data.</p>\n",
    " <h4>   Make a hypothesis that explains the  patterns of changing training and test scores you see, and be ready to discuss this in class.</h4></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for trSetSize in (100, 600, 1000, 6000, 10000, 50000):\n",
    "    split = trSetSize / 60000\n",
    "    _, X_train_small, _, y_train_small = train_test_split(\n",
    "        X_train, y_train, test_size=split, stratify=y_train\n",
    "    )\n",
    "    smallMnistMLP = MLPClassifier(\n",
    "        hidden_layer_sizes=(16),\n",
    "        max_iter=25,\n",
    "        alpha=1e-4,\n",
    "        solver=\"sgd\",\n",
    "        verbose=0,\n",
    "        random_state=10,\n",
    "        learning_rate_init=0.1,\n",
    "    )\n",
    "\n",
    "    # put a loop of n runs here\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        smallMnistMLP.fit(X_train_small, y_train_small)\n",
    "    print(f\"With a training set of {trSetSize} examples\")\n",
    "    print(\n",
    "        f\"    Training set accuracy: {100*smallMnistMLP.score(X_train_small, y_train_small)}%\"\n",
    "    )\n",
    "    print(f\"    Test set accuracy: {100*smallMnistMLP.score(X_test, y_test)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\" style=\"color:black\"><h2> (Stretch) Activity 3.5: Gathering evidence for your hypothesis.</h2>\n",
    "<ol>\n",
    "    <li> Copy and paste the code from the previous cell into the cell below. </li>\n",
    "    <li> <b>Edit</b> the code by: <ul>\n",
    "        <li> Adding an array called results with 4 columns and 30 rows, initialised to zero (hint: np,zeros). </li>\n",
    "        <li> Adding a loop so that it runs the experiment for each training set size  5 times.</li>\n",
    "        <li> saving the training and test accuracy from each run into a seperate row in your new  array.</li>\n",
    "        <li> Store the training set size in results column 0, run number in column 1, training accuracy in column 2 and test accuracy in column 3.</li>\n",
    "     </ul>\n",
    "    <li> Use matplotlib to make a plot with training set size on the x-axis and accuracy on the y-axis</li>\n",
    "        <li> Plot your results as two different lines on your plot, with error bars for each.</li>\n",
    "        </ol>\n",
    "        <p> <b>  HINT: google is good to find code snippets to make plots with.</b></p.</div>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> Please save your work (click the save icon) then shutdown the notebook when you have finished with this tutorial (menu->file->close and shutdown notebook</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> Remember to download and save your work if you are not running this notebook locally.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
